{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d92426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afdb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de359b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp =pd.read_csv('yelp.csv')\n",
    "df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f02c886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'restaurant', 'rank', 'point', 'review_n', 'username',\n",
       "       'location', 'has_profile', 'friend', 'review', 'photo', 'text', 'date',\n",
       "       'rating', 'fake', 'local', 'compound', 'positive', 'negative',\n",
       "       'neutral', 'word_count', 'sentence_length', 'adj_POS', 'I_pronoun',\n",
       "       'past_tense', 'rating_dev', 'ttr', 'verb_POS', 'pron_POS', 'adv_POS',\n",
       "       'prep_POS', 'conj_POS', 'you_pronoun', '3rd_pronoun', 'present_tense',\n",
       "       'future_tense'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = yelp.drop(columns=['Unnamed: 0'])\n",
    "yelp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac9cb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>rank</th>\n",
       "      <th>point</th>\n",
       "      <th>review_n</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>has_profile</th>\n",
       "      <th>friend</th>\n",
       "      <th>review</th>\n",
       "      <th>...</th>\n",
       "      <th>ttr</th>\n",
       "      <th>verb_POS</th>\n",
       "      <th>pron_POS</th>\n",
       "      <th>adv_POS</th>\n",
       "      <th>prep_POS</th>\n",
       "      <th>conj_POS</th>\n",
       "      <th>you_pronoun</th>\n",
       "      <th>3rd_pronoun</th>\n",
       "      <th>present_tense</th>\n",
       "      <th>future_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Ernesto B.</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Katrina F.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551220</td>\n",
       "      <td>0.228022</td>\n",
       "      <td>0.123626</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.021978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Mario V.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.130515</td>\n",
       "      <td>0.075368</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.023897</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.038603</td>\n",
       "      <td>0.016544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Giselle A.</td>\n",
       "      <td>Martinez, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.061224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Seth E.</td>\n",
       "      <td>Dublin, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649746</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.095506</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      city     restaurant  rank  point  review_n    username  \\\n",
       "0  Alameda  Jong Ga House   236    4.0    2300.0  Ernesto B.   \n",
       "1  Alameda  Jong Ga House   236    4.0    2300.0  Katrina F.   \n",
       "2  Alameda  Jong Ga House   236    4.0    2300.0    Mario V.   \n",
       "3  Alameda  Jong Ga House   236    4.0    2300.0  Giselle A.   \n",
       "4  Alameda  Jong Ga House   236    4.0    2300.0     Seth E.   \n",
       "\n",
       "            location  has_profile  friend  review  ...       ttr  verb_POS  \\\n",
       "0        Oakland, CA          0.0     0.0     1.0  ...  0.840000  0.100000   \n",
       "1  San Francisco, CA          1.0   914.0   101.0  ...  0.551220  0.228022   \n",
       "2  San Francisco, CA          1.0    86.0    13.0  ...  0.497600  0.205882   \n",
       "3       Martinez, CA          1.0   240.0    15.0  ...  0.789474  0.183673   \n",
       "4         Dublin, CA          1.0   249.0    40.0  ...  0.649746  0.224719   \n",
       "\n",
       "   pron_POS   adv_POS  prep_POS  conj_POS  you_pronoun  3rd_pronoun  \\\n",
       "0  0.000000  0.100000  0.100000  0.000000     0.000000     0.000000   \n",
       "1  0.123626  0.057692  0.129121  0.043956     0.013736     0.041209   \n",
       "2  0.130515  0.075368  0.117647  0.023897     0.007353     0.031250   \n",
       "3  0.091837  0.091837  0.112245  0.030612     0.040816     0.010204   \n",
       "4  0.095506  0.101124  0.089888  0.028090     0.022472     0.011236   \n",
       "\n",
       "   present_tense  future_tense  \n",
       "0       0.050000      0.000000  \n",
       "1       0.032967      0.021978  \n",
       "2       0.038603      0.016544  \n",
       "3       0.061224      0.061224  \n",
       "4       0.028090      0.000000  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "description =yelp.head()\n",
    "display(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b28dce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review_count</th>\n",
       "      <th>fake_review_count</th>\n",
       "      <th>percent</th>\n",
       "      <th>percent_ne_non</th>\n",
       "      <th>percent_po_non</th>\n",
       "      <th>percent_ne_re</th>\n",
       "      <th>percent_po_re</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Jong Ga House</td>\n",
       "      <td>2325</td>\n",
       "      <td>125</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.433934</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Brendas Oakland</td>\n",
       "      <td>1064</td>\n",
       "      <td>41</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.109415</td>\n",
       "      <td>0.455471</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Homeroom</td>\n",
       "      <td>6486</td>\n",
       "      <td>821</td>\n",
       "      <td>0.112358</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.585871</td>\n",
       "      <td>0.044376</td>\n",
       "      <td>0.437908</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Yojimbo</td>\n",
       "      <td>1673</td>\n",
       "      <td>66</td>\n",
       "      <td>0.037953</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.092086</td>\n",
       "      <td>0.391367</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>Quinns Lighthouse</td>\n",
       "      <td>1030</td>\n",
       "      <td>67</td>\n",
       "      <td>0.061076</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.257525</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city         restaurant  review_count  fake_review_count   percent  \\\n",
       "0  Alameda      Jong Ga House          2325                125  0.051020   \n",
       "1  Alameda    Brendas Oakland          1064                 41  0.037104   \n",
       "2  Alameda           Homeroom          6486                821  0.112358   \n",
       "3  Alameda            Yojimbo          1673                 66  0.037953   \n",
       "4  Alameda  Quinns Lighthouse          1030                 67  0.061076   \n",
       "\n",
       "   percent_ne_non  percent_po_non  percent_ne_re  percent_po_re  point  \n",
       "0        0.016260        0.609756       0.045546       0.433934    4.0  \n",
       "1        0.076923        0.692308       0.109415       0.455471    3.9  \n",
       "2        0.032887        0.585871       0.044376       0.437908    4.1  \n",
       "3        0.092308        0.615385       0.092086       0.391367    3.9  \n",
       "4        0.230769        0.446154       0.128205       0.257525    3.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "description =df.head()\n",
    "display(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e22a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_review_count'] = df['review_count'] + df['fake_review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dd08761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>fake_review_count</th>\n",
       "      <th>percent</th>\n",
       "      <th>percent_ne_non</th>\n",
       "      <th>percent_po_non</th>\n",
       "      <th>percent_ne_re</th>\n",
       "      <th>percent_po_re</th>\n",
       "      <th>point</th>\n",
       "      <th>total_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>728.028000</td>\n",
       "      <td>65.588000</td>\n",
       "      <td>0.072025</td>\n",
       "      <td>0.127302</td>\n",
       "      <td>0.579332</td>\n",
       "      <td>0.089978</td>\n",
       "      <td>0.509796</td>\n",
       "      <td>4.003600</td>\n",
       "      <td>793.61600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1221.013614</td>\n",
       "      <td>210.216087</td>\n",
       "      <td>0.049926</td>\n",
       "      <td>0.137917</td>\n",
       "      <td>0.238163</td>\n",
       "      <td>0.097690</td>\n",
       "      <td>0.172827</td>\n",
       "      <td>0.505431</td>\n",
       "      <td>1412.48112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.023955</td>\n",
       "      <td>0.456512</td>\n",
       "      <td>0.039701</td>\n",
       "      <td>0.400763</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>179.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.063219</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.064110</td>\n",
       "      <td>0.501859</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>426.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>847.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.087279</td>\n",
       "      <td>0.186342</td>\n",
       "      <td>0.737395</td>\n",
       "      <td>0.108675</td>\n",
       "      <td>0.631243</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>904.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18556.000000</td>\n",
       "      <td>4389.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22945.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_count  fake_review_count     percent  percent_ne_non  \\\n",
       "count    750.000000         750.000000  750.000000      750.000000   \n",
       "mean     728.028000          65.588000    0.072025        0.127302   \n",
       "std     1221.013614         210.216087    0.049926        0.137917   \n",
       "min        1.000000           0.000000    0.000000        0.000000   \n",
       "25%      167.000000          10.000000    0.044444        0.023955   \n",
       "50%      398.000000          26.000000    0.063219        0.090909   \n",
       "75%      847.000000          62.000000    0.087279        0.186342   \n",
       "max    18556.000000        4389.000000    0.500000        1.000000   \n",
       "\n",
       "       percent_po_non  percent_ne_re  percent_po_re       point  \\\n",
       "count      750.000000     750.000000     750.000000  750.000000   \n",
       "mean         0.579332       0.089978       0.509796    4.003600   \n",
       "std          0.238163       0.097690       0.172827    0.505431   \n",
       "min          0.000000       0.000000       0.000000    1.000000   \n",
       "25%          0.456512       0.039701       0.400763    3.800000   \n",
       "50%          0.591229       0.064110       0.501859    4.100000   \n",
       "75%          0.737395       0.108675       0.631243    4.300000   \n",
       "max          1.000000       1.000000       1.000000    5.000000   \n",
       "\n",
       "       total_review_count  \n",
       "count           750.00000  \n",
       "mean            793.61600  \n",
       "std            1412.48112  \n",
       "min               1.00000  \n",
       "25%             179.25000  \n",
       "50%             426.00000  \n",
       "75%             904.50000  \n",
       "max           22945.00000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8558a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # 先解码 HTML 实体编码，然后再去除非 ASCII 字符\n",
    "    text = html.unescape(str(text))\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# 在应用函数之前，确保 'text' 列中的所有值都是字符串\n",
    "df['restaurant'] = df['restaurant'].apply(remove_non_ascii)\n",
    "df['city'] = df['city'].apply(remove_non_ascii)\n",
    "yelp['restaurant'] = yelp['restaurant'].apply(remove_non_ascii)\n",
    "yelp['city'] = yelp['city'].apply(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d65245",
   "metadata": {},
   "source": [
    "# merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5d6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(yelp, df, on=['city', 'restaurant'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da11eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_drop = ['point_x', 'review_n']\n",
    "\n",
    "# 使用 drop 方法删除指定的变量\n",
    "merge = merge.drop(variables_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe6aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.rename(columns={'point_y': 'point'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886cb7b",
   "metadata": {},
   "source": [
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af79a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop(index=244667, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f699f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop(index=296705, inplace=True)\n",
    "merge.drop(index=296707, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd81311",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rows_with_greater_than_1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m[df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating_dev\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 打印符合条件的行的所有变量的取值情况\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madv_POS\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "rows_with_greater_than_1 = df1[df1['rating_dev'] > 10]\n",
    "\n",
    "# 打印符合条件的行的所有变量的取值情况\n",
    "print(\"Rows with 'adv_POS' > 1:\")\n",
    "display(rows_with_greater_than_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b69812",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop(index=219837, inplace=True)\n",
    "merge.drop(index=347203, inplace=True)\n",
    "merge.drop(index=9570, inplace=True)\n",
    "merge.drop(index=74254, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f111c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'restaurant', 'rank', 'username', 'location', 'has_profile',\n",
       "       'friend', 'review', 'photo', 'text', 'date', 'rating', 'fake', 'local',\n",
       "       'compound', 'positive', 'negative', 'neutral', 'word_count',\n",
       "       'sentence_length', 'adj_POS', 'I_pronoun', 'past_tense', 'rating_dev',\n",
       "       'ttr', 'verb_POS', 'pron_POS', 'adv_POS', 'prep_POS', 'conj_POS',\n",
       "       'you_pronoun', '3rd_pronoun', 'present_tense', 'future_tense',\n",
       "       'review_count', 'fake_review_count', 'percent', 'percent_ne_non',\n",
       "       'percent_po_non', 'percent_ne_re', 'percent_po_re', 'point',\n",
       "       'total_review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43039cf1",
   "metadata": {},
   "source": [
    "处理变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9940132",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_abs = ['rating_dev']\n",
    "\n",
    "# 对指定的变量取绝对值，并替换原数据\n",
    "merge[variables_to_abs] = merge[variables_to_abs].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d6aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['has_profile'] = 1 - merge['has_profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551e0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['non_recommend'] = merge['fake']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76b31e1f",
   "metadata": {},
   "source": [
    "merge['uers_non'] = 0\n",
    "\n",
    "# 将满足条件的行的 'fri_ph' 列的值设置为1\n",
    "merge.loc[(merge['friend'] == 0) & (merge['photo'] == 0) & (merge['review'] <= 5) , 'uers_non'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37819998",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_drop = ['city', 'restaurant', 'username', 'location','text', 'date', 'percent_ne_non',\n",
    "       'percent_po_non']\n",
    "\n",
    "# 使用 drop 方法删除指定的变量\n",
    "merge = merge.drop(variables_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cfbc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['5'] = merge['rating'].apply(lambda x: 1 if x == 5 else 0)\n",
    "merge['4'] = merge['rating'].apply(lambda x: 1 if x == 4 else 0)\n",
    "merge['2'] = merge['rating'].apply(lambda x: 1 if x == 2 else 0)\n",
    "merge['1'] = merge['rating'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d7302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank', 'has_profile', 'friend', 'review', 'photo', 'rating', 'fake',\n",
       "       'local', 'compound', 'positive', 'negative', 'neutral', 'word_count',\n",
       "       'sentence_length', 'adj_POS', 'I_pronoun', 'past_tense', 'rating_dev',\n",
       "       'ttr', 'verb_POS', 'pron_POS', 'adv_POS', 'prep_POS', 'conj_POS',\n",
       "       'you_pronoun', '3rd_pronoun', 'present_tense', 'future_tense',\n",
       "       'review_count', 'fake_review_count', 'percent', 'percent_ne_re',\n",
       "       'percent_po_re', 'point', 'total_review_count', 'non_recommend', '5',\n",
       "       '4', '2', '1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444ace7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rest_review_count'] = df['total_review_count']\n",
    "merge['user_review_count'] = merge['review']\n",
    "merge['user_friend_count'] = merge['friend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c0023d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word_count</th>\n",
       "      <th>rest_review_count</th>\n",
       "      <th>point</th>\n",
       "      <th>user_friend_count</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>has_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.03</td>\n",
       "      <td>96.17</td>\n",
       "      <td>793.62</td>\n",
       "      <td>4.00</td>\n",
       "      <td>114.98</td>\n",
       "      <td>124.80</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.24</td>\n",
       "      <td>94.56</td>\n",
       "      <td>1412.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>300.22</td>\n",
       "      <td>399.57</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>179.25</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>426.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>13.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>904.50</td>\n",
       "      <td>4.30</td>\n",
       "      <td>114.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1728.00</td>\n",
       "      <td>22945.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>20415.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  word_count  rest_review_count  point  user_friend_count  \\\n",
       "mean    4.03       96.17             793.62   4.00             114.98   \n",
       "std     1.24       94.56            1412.48   0.51             300.22   \n",
       "min     0.00        1.00               1.00   1.00               0.00   \n",
       "25%     4.00       34.00             179.25   3.80               0.00   \n",
       "50%     4.00       66.00             426.00   4.10              13.00   \n",
       "75%     5.00      125.00             904.50   4.30             114.00   \n",
       "max     5.00     1728.00           22945.00   5.00            5000.00   \n",
       "\n",
       "      user_review_count  has_profile  \n",
       "mean             124.80         0.72  \n",
       "std              399.57         0.45  \n",
       "min                0.00         0.00  \n",
       "25%                8.00         0.00  \n",
       "50%               28.00         1.00  \n",
       "75%              101.00         1.00  \n",
       "max            20415.00         1.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_order = [ 'rating', 'word_count','rest_review_count', 'point', 'user_friend_count', 'user_review_count', 'has_profile']\n",
    "\n",
    "# 对merge的子集进行描述性统计\n",
    "merge_describe = merge[['rating', 'word_count', 'user_review_count', 'user_friend_count', 'has_profile']].describe()\n",
    "\n",
    "# 对df的子集进行描述性统计\n",
    "df_describe = df[['rest_review_count', 'point']].describe()\n",
    "\n",
    "# 合并统计结果，但保持调整后的顺序\n",
    "combined_describe_adjusted = pd.concat([df_describe, merge_describe], axis=1)[adjusted_order]\n",
    "\n",
    "# 移除count行并四舍五入到两位小数\n",
    "combined_describe_adjusted_no_count = combined_describe_adjusted.drop('count').round(2)\n",
    "\n",
    "# 显示调整顺序后且移除了count行的描述性统计表格\n",
    "combined_describe_adjusted_no_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc73b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_review_count</th>\n",
       "      <th>point</th>\n",
       "      <th>friend</th>\n",
       "      <th>review</th>\n",
       "      <th>has_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486749.00</td>\n",
       "      <td>486749.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>486749.00</td>\n",
       "      <td>486749.00</td>\n",
       "      <td>486749.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>96.17</td>\n",
       "      <td>4.03</td>\n",
       "      <td>793.62</td>\n",
       "      <td>4.00</td>\n",
       "      <td>114.98</td>\n",
       "      <td>124.80</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>94.56</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1412.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>300.22</td>\n",
       "      <td>399.57</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>179.25</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>426.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>13.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>125.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>904.50</td>\n",
       "      <td>4.30</td>\n",
       "      <td>114.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1728.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>22945.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>20415.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count     rating  total_review_count   point     friend  \\\n",
       "count   486749.00  486749.00              750.00  750.00  486749.00   \n",
       "mean        96.17       4.03              793.62    4.00     114.98   \n",
       "std         94.56       1.24             1412.48    0.51     300.22   \n",
       "min          1.00       0.00                1.00    1.00       0.00   \n",
       "25%         34.00       4.00              179.25    3.80       0.00   \n",
       "50%         66.00       4.00              426.00    4.10      13.00   \n",
       "75%        125.00       5.00              904.50    4.30     114.00   \n",
       "max       1728.00       5.00            22945.00    5.00    5000.00   \n",
       "\n",
       "          review  has_profile  \n",
       "count  486749.00    486749.00  \n",
       "mean      124.80         0.72  \n",
       "std       399.57         0.45  \n",
       "min         0.00         0.00  \n",
       "25%         8.00         0.00  \n",
       "50%        28.00         1.00  \n",
       "75%       101.00         1.00  \n",
       "max     20415.00         1.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调整变量顺序\n",
    "# 先排列 df 的列，然后是 merge 的列\n",
    "adjusted_order = ['word_count',  \n",
    "                  'rating','total_review_count', 'point', \n",
    "                   'friend', 'review', 'has_profile']\n",
    "\n",
    "# 对merge的子集进行描述性统计\n",
    "merge_describe = merge[['non_recommend', 'word_count', 'rating_dev', 'rating', 'friend', 'review', 'has_profile']].describe()\n",
    "\n",
    "# 对df的子集进行描述性统计\n",
    "df_describe = df[['total_review_count', 'point']].describe()\n",
    "\n",
    "# 合并统计结果，但保持调整后的顺序\n",
    "combined_describe_adjusted = pd.concat([df_describe, merge_describe], axis=1)[adjusted_order]\n",
    "\n",
    "# 显示调整顺序后的描述性统计表格\n",
    "combined_describe_adjusted.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ee9a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 计算 'a' 的每个独特值的频率\n",
    "a_counts = df['total_review_count'].value_counts().sort_index()\n",
    "\n",
    "# 2. 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "a_counts.plot(kind='line')\n",
    "plt.title('Line Plot of the Distribution of Variable \"a\"')\n",
    "plt.xlabel('Value of a')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a47eb",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaecefdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "merge['total_review_count'] = np.where(merge['total_review_count'] != 0, np.log(merge['total_review_count']), 0)\n",
    "merge['word_count'] = np.where(merge['word_count'] != 0, np.log(merge['word_count']), 0)\n",
    "merge['photo'] = np.where(merge['photo'] != 0, np.log(merge['photo']), 0)\n",
    "merge['review'] = np.where(merge['review'] != 0, np.log(merge['review']), 0)\n",
    "merge['friend'] = np.where(merge['friend'] != 0, np.log(merge['friend']), 0)\n",
    "merge['review_count'] = np.where(merge['review_count'] != 0, np.log(merge['review_count']), 0)\n",
    "#merge['rank'] = np.where(merge['rank'] != 0, np.log(merge['rank']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e4ca867",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv(\"D:/论文记录/shuju/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "da0fc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_yelp = merge[['1','2','4','5','word_count','review','photo','fake']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74decd7d",
   "metadata": {},
   "source": [
    "X = ML_yelp.drop('fake', axis=1)\n",
    "y = ML_yelp['fake']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "X_train_set, X_test_data = train_test_split(X_resampled, test_size=0.2, random_state=42)\n",
    "X_test_set, X_validation_set = train_test_split(X_test_data, test_size=0.2, random_state=42)\n",
    "y_train_set, y_test_data = train_test_split(y_resampled, test_size=0.2, random_state=42)\n",
    "y_test_set, y_validation_set = train_test_split(y_test_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "76ea3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficients:\n",
      "[[ 0.28554035 -0.05566672  0.17563544 -0.0233248  -1.12419063 -0.5237229\n",
      "  -0.1625711 ]]\n",
      "Intercept: [3.49905347]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.238951\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   fake   No. Observations:               486750\n",
      "Model:                          Logit   Df Residuals:                   486742\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Fri, 08 Dec 2023   Pseudo R-squ.:                  0.2611\n",
      "Time:                        20:59:12   Log-Likelihood:            -1.1631e+05\n",
      "converged:                       True   LL-Null:                   -1.5741e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.4991      0.035     99.705      0.000       3.430       3.568\n",
      "1              0.2857      0.028     10.123      0.000       0.230       0.341\n",
      "2             -0.0556      0.033     -1.673      0.094      -0.121       0.010\n",
      "4              0.1758      0.025      7.148      0.000       0.128       0.224\n",
      "5             -0.0232      0.023     -1.018      0.309      -0.068       0.021\n",
      "word_count    -1.1242      0.007   -160.581      0.000      -1.138      -1.111\n",
      "review        -0.5237      0.005   -103.982      0.000      -0.534      -0.514\n",
      "photo         -0.1626      0.005    -31.032      0.000      -0.173      -0.152\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Replace 'your_data_frame' with the actual DataFrame containing your dataset\n",
    "# Example: df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assume 'fake' is the column you want to predict\n",
    "X = ML_yelp.drop('fake', axis=1)\n",
    "#X = ML_yelp[[]]\n",
    "y = ML_yelp['fake']\n",
    "\n",
    "# Create a logistic regression model with sklearn\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X, y)\n",
    "\n",
    "# Display the logistic regression coefficients\n",
    "print(\"Logistic Regression Coefficients:\")\n",
    "print(logistic_model.coef_)\n",
    "print(\"Intercept:\", logistic_model.intercept_)\n",
    "\n",
    "# Create a logistic regression model with statsmodels\n",
    "X = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Display the logistic regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6e6fa578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = merge[ ['rank', 'has_profile', 'friend', 'review', 'photo', 'rating', \n",
    "       'local', 'compound', 'positive', 'negative', 'neutral', 'word_count',\n",
    "       'adj_POS', 'I_pronoun', 'past_tense', 'rating_dev',\n",
    "       'verb_POS', 'pron_POS', 'adv_POS', 'prep_POS', 'conj_POS',\n",
    "       'point', 'total_review_count', '5', '4', '2', '1'] ]\n",
    "y = merge['fake']\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "feature_importance = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "\n",
    "feature_importance.nlargest(40).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354ab07",
   "metadata": {},
   "source": [
    "# machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a19bdd",
   "metadata": {},
   "source": [
    "# XGBoots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511af9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8b33090",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_yelp = merge[['review_count', 'percent', 'point','positive_dev', 'negative_dev',\n",
    "       'rating_dev','word_count', 'word_25', 'ttr', 'adj_POS', 'verb_POS', 'pron_POS','adv_POS', 'I_pronoun', 'past_tense','compound',\n",
    "       'review', 'photo', 'friend' ,'fake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6f77f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ML_yelp, test_size=0.2, random_state=42)\n",
    "train_set, validation_set = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32dc2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop('fake', axis=1)\n",
    "y_train = train_set['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab568d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    280558\n",
      "1.0     30962\n",
      "Name: fake, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_values = y_train.value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8f34087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     70046\n",
      "         1.0       0.74      0.33      0.46      7834\n",
      "\n",
      "    accuracy                           0.92     77880\n",
      "   macro avg       0.84      0.66      0.71     77880\n",
      "weighted avg       0.91      0.92      0.91     77880\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     87845\n",
      "         1.0       0.74      0.33      0.46      9505\n",
      "\n",
      "    accuracy                           0.92     97350\n",
      "   macro avg       0.84      0.66      0.71     97350\n",
      "weighted avg       0.91      0.92      0.91     97350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 XGBoost 模型并传递最优参数\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. 在验证集上进行预测\n",
    "X_validation = validation_set.drop('fake', axis=1)\n",
    "y_validation = validation_set['fake']\n",
    "y_pred_validation = xgb_model.predict(X_validation)\n",
    "\n",
    "X_test = test_data.drop('fake', axis=1)\n",
    "y_test = test_data['fake']\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19a286fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# 创建XGBoost模型\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# 使用网格搜索进行交叉验证\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48186817",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfa04bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "532db308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     70046\n",
      "         1.0       0.77      0.31      0.44      7834\n",
      "\n",
      "    accuracy                           0.92     77880\n",
      "   macro avg       0.85      0.65      0.70     77880\n",
      "weighted avg       0.91      0.92      0.91     77880\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     87845\n",
      "         1.0       0.78      0.31      0.44      9505\n",
      "\n",
      "    accuracy                           0.92     97350\n",
      "   macro avg       0.85      0.65      0.70     97350\n",
      "weighted avg       0.91      0.92      0.91     97350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest model\n",
    "#best_params = {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 188}\n",
    "#rf_model = RandomForestClassifier(**best_params)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set predictions\n",
    "X_validation = validation_set.drop('fake', axis=1)\n",
    "y_validation = validation_set['fake']\n",
    "y_pred_validation = rf_model.predict(X_validation)\n",
    "\n",
    "# Test set predictions\n",
    "X_test = test_data.drop('fake', axis=1)\n",
    "y_test = test_data['fake']\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d12e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 188}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 定义参数范围\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# 创建随机森林模型\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 使用随机搜索进行交叉验证\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4d894",
   "metadata": {},
   "source": [
    "# logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7d45d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95     70093\n",
      "         1.0       0.65      0.12      0.21      7788\n",
      "\n",
      "    accuracy                           0.91     77881\n",
      "   macro avg       0.78      0.56      0.58     77881\n",
      "weighted avg       0.89      0.91      0.88     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95     87731\n",
      "         1.0       0.65      0.12      0.20      9620\n",
      "\n",
      "    accuracy                           0.91     97351\n",
      "   macro avg       0.78      0.56      0.57     97351\n",
      "weighted avg       0.89      0.91      0.88     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 Logistic Regression 模型\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = logreg_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = logreg_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c87f6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.09936799 0.06211802 0.15525053 0.08876403        nan        nan\n",
      " 0.23138165 0.09094336 0.22438659 0.09366194        nan        nan\n",
      " 0.25438431 0.09412567 0.25102542 0.09452107        nan        nan\n",
      " 0.25737328 0.09440471 0.25781972 0.09451756        nan        nan\n",
      " 0.25818634 0.0945788  0.25705919 0.0945183         nan        nan\n",
      " 0.25895313 0.09457603 0.25653031 0.0945183         nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95     87731\n",
      "         1.0       0.69      0.16      0.26      9620\n",
      "\n",
      "    accuracy                           0.91     97351\n",
      "   macro avg       0.80      0.58      0.61     97351\n",
      "weighted avg       0.89      0.91      0.88     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(logreg_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# 运行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_logreg_model = grid_search.best_estimator_\n",
    "y_pred = best_logreg_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b22f3a",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22d40e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95     70093\n",
      "         1.0       0.66      0.29      0.41      7788\n",
      "\n",
      "    accuracy                           0.91     77881\n",
      "   macro avg       0.79      0.64      0.68     77881\n",
      "weighted avg       0.90      0.91      0.90     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95     87731\n",
      "         1.0       0.66      0.30      0.41      9620\n",
      "\n",
      "    accuracy                           0.92     97351\n",
      "   macro avg       0.79      0.64      0.68     97351\n",
      "weighted avg       0.90      0.92      0.90     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7)  # 5是一个示例，你可以根据需要调整\n",
    "\n",
    "# 训练模型\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = knn_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = knn_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3497590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "\n",
    "# 创建 KNN 模型\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# 使用网格搜索进行交叉验证\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cddf803",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12559785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "svm_model = SVC(kernel='rbf', gamma='scale') \n",
    "\n",
    "# 训练模型\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = svm_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc00a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 创建 SVM 模型\n",
    "svm_model = SVC()\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "# 使用 GridSearchCV 进行交叉验证\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54267c",
   "metadata": {},
   "source": [
    "# naive_bayes-BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d661db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90     70093\n",
      "         1.0       0.30      0.58      0.39      7788\n",
      "\n",
      "    accuracy                           0.82     77881\n",
      "   macro avg       0.62      0.71      0.64     77881\n",
      "weighted avg       0.88      0.82      0.84     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90     87731\n",
      "         1.0       0.30      0.58      0.39      9620\n",
      "\n",
      "    accuracy                           0.82     97351\n",
      "   macro avg       0.62      0.71      0.64     97351\n",
      "weighted avg       0.88      0.82      0.85     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nb_model = BernoulliNB()\n",
    "\n",
    "# 训练模型\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = nb_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = nb_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81a02483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 10, 'binarize': 0.0}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90     87731\n",
      "         1.0       0.30      0.58      0.39      9620\n",
      "\n",
      "    accuracy                           0.82     97351\n",
      "   macro avg       0.62      0.71      0.64     97351\n",
      "weighted avg       0.88      0.82      0.85     97351\n",
      "\n",
      "Confusion Matrix:\n",
      "[[74481 13250]\n",
      " [ 4048  5572]]\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb_model = BernoulliNB()\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'binarize': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(bernoulli_nb_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# 运行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 使用最佳参数的模型进行预测\n",
    "best_bernoulli_nb_model = grid_search.best_estimator_\n",
    "y_pred = best_bernoulli_nb_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fb7a3",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01766e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93     70093\n",
      "         1.0       0.37      0.41      0.39      7788\n",
      "\n",
      "    accuracy                           0.87     77881\n",
      "   macro avg       0.65      0.67      0.66     77881\n",
      "weighted avg       0.88      0.87      0.88     77881\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64717  5376]\n",
      " [ 4564  3224]]\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93     87731\n",
      "         1.0       0.38      0.42      0.40      9620\n",
      "\n",
      "    accuracy                           0.88     97351\n",
      "   macro avg       0.66      0.67      0.67     97351\n",
      "weighted avg       0.88      0.88      0.88     97351\n",
      "\n",
      "Confusion Matrix:\n",
      "[[81292  6439]\n",
      " [ 5599  4021]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = tree_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = tree_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "175baaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     87731\n",
      "         1.0       0.74      0.29      0.42      9620\n",
      "\n",
      "    accuracy                           0.92     97351\n",
      "   macro avg       0.84      0.64      0.69     97351\n",
      "weighted avg       0.91      0.92      0.90     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(decision_tree_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# 运行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 使用最佳参数的模型进行预测\n",
    "best_decision_tree_model = grid_search.best_estimator_\n",
    "y_pred = best_decision_tree_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898b05d",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8823308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_yelp = merge[['review_count', 'percent', 'point','positive_dev', 'negative_dev',\n",
    "       'rating_dev','word_count', 'word_25', 'ttr', 'adj_POS', 'verb_POS', 'pron_POS','adv_POS', 'I_pronoun', 'past_tense','compound',\n",
    "       'review', 'photo', 'friend' ,'fake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70e24d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ML_yelp.drop('fake', axis=1)\n",
    "y = ML_yelp['fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12f957f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a330e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_test_data = train_test_split(X_resampled, test_size=0.2, random_state=42)\n",
    "X_test_set, X_validation_set = train_test_split(X_test_data, test_size=0.2, random_state=42)\n",
    "y_train_set, y_test_data = train_test_split(y_resampled, test_size=0.2, random_state=42)\n",
    "y_test_set, y_validation_set = train_test_split(y_test_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "979b4fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94     17465\n",
      "         1.0       0.96      0.91      0.94     17611\n",
      "\n",
      "    accuracy                           0.94     35076\n",
      "   macro avg       0.94      0.94      0.94     35076\n",
      "weighted avg       0.94      0.94      0.94     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94     70120\n",
      "         1.0       0.96      0.91      0.94     70184\n",
      "\n",
      "    accuracy                           0.94    140304\n",
      "   macro avg       0.94      0.94      0.94    140304\n",
      "weighted avg       0.94      0.94      0.94    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 5. 在验证集上进行预测\n",
    "y_pred_validation = xgb_model.predict(X_validation_set)\n",
    "\n",
    "y_pred_test = xgb_model.predict(X_test_set)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cddcd0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# 创建XGBoost模型\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# 使用网格搜索进行交叉验证\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce50db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95     17465\n",
      "         1.0       0.96      0.94      0.95     17611\n",
      "\n",
      "    accuracy                           0.95     35076\n",
      "   macro avg       0.95      0.95      0.95     35076\n",
      "weighted avg       0.95      0.95      0.95     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95     70120\n",
      "         1.0       0.96      0.94      0.95     70184\n",
      "\n",
      "    accuracy                           0.95    140304\n",
      "   macro avg       0.95      0.95      0.95    140304\n",
      "weighted avg       0.95      0.95      0.95    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# Validation set predictions\n",
    "y_pred_validation = rf_model.predict(X_validation_set)\n",
    "\n",
    "# Test set predictions\n",
    "y_pred_test = rf_model.predict(X_test_set)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09739f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 使用随机搜索进行交叉验证\u001b[39;00m\n\u001b[0;32m     17\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(rf_model, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 输出最佳参数\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 定义参数范围\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# 创建随机森林模型\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 使用随机搜索进行交叉验证\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1')\n",
    "random_search.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a86d6c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.65      0.70     17465\n",
      "         1.0       0.70      0.80      0.75     17611\n",
      "\n",
      "    accuracy                           0.73     35076\n",
      "   macro avg       0.73      0.73      0.72     35076\n",
      "weighted avg       0.73      0.73      0.72     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.66      0.71     70120\n",
      "         1.0       0.70      0.80      0.75     70184\n",
      "\n",
      "    accuracy                           0.73    140304\n",
      "   macro avg       0.73      0.73      0.73    140304\n",
      "weighted avg       0.73      0.73      0.73    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 Logistic Regression 模型\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "logreg_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = logreg_model.predict(X_validation_set)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = logreg_model.predict(X_test_set)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0b53aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87     17465\n",
      "         1.0       0.83      0.97      0.89     17611\n",
      "\n",
      "    accuracy                           0.88     35076\n",
      "   macro avg       0.89      0.88      0.88     35076\n",
      "weighted avg       0.89      0.88      0.88     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.79      0.87     70120\n",
      "         1.0       0.83      0.97      0.89     70184\n",
      "\n",
      "    accuracy                           0.88    140304\n",
      "   macro avg       0.89      0.88      0.88    140304\n",
      "weighted avg       0.89      0.88      0.88    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # 5是一个示例，你可以根据需要调整\n",
    "\n",
    "# 训练模型\n",
    "knn_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = knn_model.predict(X_validation_set)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = knn_model.predict(X_test_set)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62e2bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.74      0.72     17465\n",
      "         1.0       0.73      0.69      0.71     17611\n",
      "\n",
      "    accuracy                           0.71     35076\n",
      "   macro avg       0.71      0.71      0.71     35076\n",
      "weighted avg       0.71      0.71      0.71     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.74      0.72     70120\n",
      "         1.0       0.73      0.69      0.70     70184\n",
      "\n",
      "    accuracy                           0.71    140304\n",
      "   macro avg       0.71      0.71      0.71    140304\n",
      "weighted avg       0.71      0.71      0.71    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nb_model = BernoulliNB()\n",
    "\n",
    "# 训练模型\n",
    "nb_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = nb_model.predict(X_validation_set)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = nb_model.predict(X_test_set)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b03b53f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91     17465\n",
      "         1.0       0.90      0.92      0.91     17611\n",
      "\n",
      "    accuracy                           0.91     35076\n",
      "   macro avg       0.91      0.91      0.91     35076\n",
      "weighted avg       0.91      0.91      0.91     35076\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91     70120\n",
      "         1.0       0.90      0.92      0.91     70184\n",
      "\n",
      "    accuracy                           0.91    140304\n",
      "   macro avg       0.91      0.91      0.91    140304\n",
      "weighted avg       0.91      0.91      0.91    140304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "tree_model.fit(X_train_set, y_train_set)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = tree_model.predict(X_validation_set)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = tree_model.predict(X_test_set)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation_set, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test_set, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6bb07",
   "metadata": {},
   "source": [
    "# EasyEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a1cd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32753714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>EasyEnsembleClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">EasyEnsembleClassifier</label><div class=\"sk-toggleable__content\"><pre>EasyEnsembleClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "EasyEnsembleClassifier(random_state=42)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 RandomUnderSampler 进行欠采样\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_sampled, y_train_sampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 使用 RandomOverSampler 进行过采样\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_sampled, y_train_sampled = ros.fit_resample(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 创建 EasyEnsembleClassifier\n",
    "ee_model = EasyEnsembleClassifier(random_state=42)\n",
    "\n",
    "# 训练 EasyEnsembleClassifier\n",
    "ee_model.fit(X_train_sampled, y_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c38ee828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    30897\n",
      "1.0    30897\n",
      "Name: fake, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_values = y_train_sampled.value_counts()\n",
    "\n",
    "# 打印结果\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95fc8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87     70093\n",
      "         1.0       0.30      0.83      0.45      7788\n",
      "\n",
      "    accuracy                           0.79     77881\n",
      "   macro avg       0.64      0.81      0.66     77881\n",
      "weighted avg       0.91      0.79      0.83     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87     87731\n",
      "         1.0       0.30      0.82      0.44      9620\n",
      "\n",
      "    accuracy                           0.79     97351\n",
      "   macro avg       0.64      0.81      0.66     97351\n",
      "weighted avg       0.91      0.79      0.83     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 XGBoost 模型\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# 训练 XGBoost 模型\n",
    "xgb_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = xgb_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acb2f579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87     70093\n",
      "         1.0       0.30      0.84      0.44      7788\n",
      "\n",
      "    accuracy                           0.79     77881\n",
      "   macro avg       0.64      0.81      0.66     77881\n",
      "weighted avg       0.91      0.79      0.83     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87     87731\n",
      "         1.0       0.30      0.83      0.44      9620\n",
      "\n",
      "    accuracy                           0.79     97351\n",
      "   macro avg       0.64      0.81      0.66     97351\n",
      "weighted avg       0.91      0.79      0.83     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# Validation set predictions\n",
    "X_validation = validation_set.drop('fake', axis=1)\n",
    "y_validation = validation_set['fake']\n",
    "y_pred_validation = rf_model.predict(X_validation)\n",
    "\n",
    "# Test set predictions\n",
    "X_test = test_data.drop('fake', axis=1)\n",
    "y_test = test_data['fake']\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bc56627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10047\\Anaconda3\\envs\\new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     70093\n",
      "         1.0       0.24      0.79      0.37      7788\n",
      "\n",
      "    accuracy                           0.73     77881\n",
      "   macro avg       0.61      0.76      0.60     77881\n",
      "weighted avg       0.90      0.73      0.78     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     87731\n",
      "         1.0       0.24      0.79      0.37      9620\n",
      "\n",
      "    accuracy                           0.74     97351\n",
      "   macro avg       0.61      0.76      0.60     97351\n",
      "weighted avg       0.90      0.74      0.79     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 Logistic Regression 模型\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "logreg_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = logreg_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = logreg_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3437e98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.73      0.83     70093\n",
      "         1.0       0.24      0.76      0.37      7788\n",
      "\n",
      "    accuracy                           0.74     77881\n",
      "   macro avg       0.60      0.75      0.60     77881\n",
      "weighted avg       0.89      0.74      0.79     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.74      0.84     87731\n",
      "         1.0       0.24      0.76      0.37      9620\n",
      "\n",
      "    accuracy                           0.74     97351\n",
      "   macro avg       0.60      0.75      0.60     97351\n",
      "weighted avg       0.89      0.74      0.79     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # 5是一个示例，你可以根据需要调整\n",
    "\n",
    "# 训练模型\n",
    "knn_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = knn_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = knn_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9d9df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.72      0.83     70093\n",
      "         1.0       0.23      0.77      0.36      7788\n",
      "\n",
      "    accuracy                           0.73     77881\n",
      "   macro avg       0.60      0.74      0.59     77881\n",
      "weighted avg       0.89      0.73      0.78     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.72      0.83     87731\n",
      "         1.0       0.23      0.77      0.36      9620\n",
      "\n",
      "    accuracy                           0.73     97351\n",
      "   macro avg       0.60      0.74      0.59     97351\n",
      "weighted avg       0.89      0.73      0.78     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nb_model = BernoulliNB()\n",
    "\n",
    "# 训练模型\n",
    "nb_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = nb_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = nb_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74a92b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.73      0.83     70093\n",
      "         1.0       0.23      0.73      0.35      7788\n",
      "\n",
      "    accuracy                           0.73     77881\n",
      "   macro avg       0.59      0.73      0.59     77881\n",
      "weighted avg       0.89      0.73      0.78     77881\n",
      "\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.73      0.83     87731\n",
      "         1.0       0.23      0.73      0.35      9620\n",
      "\n",
      "    accuracy                           0.73     97351\n",
      "   macro avg       0.59      0.73      0.59     97351\n",
      "weighted avg       0.89      0.73      0.78     97351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "tree_model.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred_validation = tree_model.predict(X_validation)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred_test = tree_model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_validation, y_pred_validation))\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 设定目标采样比例\n",
    "target_ratio = 0.5  # 假设你想要正类别和负类别的样本比例为1:5\n",
    "\n",
    "# 定义 RandomOverSampler 和 RandomUnderSampler\n",
    "over_sampler = RandomOverSampler(sampling_strategy=target_ratio)\n",
    "under_sampler = RandomUnderSampler(sampling_strategy=target_ratio)\n",
    "\n",
    "# 创建 Pipeline，先进行下采样再进行上采样\n",
    "sampling_pipeline = Pipeline([\n",
    "    ('under_sampler', under_sampler),\n",
    "    ('over_sampler', over_sampler)\n",
    "])\n",
    "\n",
    "# 在训练集上应用 Pipeline\n",
    "X_resampled, y_resampled = sampling_pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建并训练模型\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
